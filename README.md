A repository about techniques to improve the reasoning capability of model.

## Reference

- Let's Verify Step by Step
- Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters
- REFT: Reasoning with REinforced Fine-Tuning
- SCoRe Training Language Models to Self-Correct via Reinforcement Learning
- Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers
- A Theoretical Understanding of Self-Correction through In-context Alignment
- Self-Taught Reasoner Bootstrapping Reasoning With Reasoning
- Scalable Online Planning via Reinforcement Learning Fine-Tuning
- [Azure OpenAI GPT-4o-mini fine-tuning tutorial](https://learn.microsoft.com/en-us/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line)
- [Customize a model with fine-tuning and DPO(Direct preference optimization)](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?tabs=azure-openai%2Cturbo%2Cpython-new&pivots=programming-language-python)
- [Azure DPO(Direct preference optimization)](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?tabs=azure-openai%2Cturbo%2Cpython-new&pivots=programming-language-python#direct-preference-optimization-dpo-preview)
- [Approaches to Improve Logical Reasoning in LLMs: The Techniques Behind the O3](docs/review2412.md)
- [Improving Logical Reasoning in LLMs: A Tool of Synthetic Data Generation using Evolutionary Learning and MCTS](https://github.com/butterluo/ImproveReasoning/blob/main/data/evolvemcts4rl/README.md)